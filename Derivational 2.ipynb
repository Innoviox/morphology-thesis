{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f5a199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 10:21:21.398652: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from nltk import edit_distance\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5fe8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fqTot</th>\n",
       "      <th>gramCat</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>Phones</th>\n",
       "      <th>morph</th>\n",
       "      <th>...</th>\n",
       "      <th>actual_lemma_pos</th>\n",
       "      <th>extra</th>\n",
       "      <th>actual_lemma_phones</th>\n",
       "      <th>spacy_lemma</th>\n",
       "      <th>nltk_lemma</th>\n",
       "      <th>derivational</th>\n",
       "      <th>process</th>\n",
       "      <th>reason</th>\n",
       "      <th>spacy_lemma_2</th>\n",
       "      <th>spacy_pos_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50518.0</td>\n",
       "      <td>P</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>P IN P@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>P IN B@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>P IN C@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>S</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73818</th>\n",
       "      <td>73818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73819</th>\n",
       "      <td>73819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73820</th>\n",
       "      <td>73820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73821</th>\n",
       "      <td>73821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73822</th>\n",
       "      <td>73822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73823 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0    fqTot  gramCat  \\\n",
       "0                 0           0.0           0.0         0.0  50518.0        P   \n",
       "1                 1           1.0           1.0         1.0   5219.0  P IN P@   \n",
       "2                 2           2.0           2.0         2.0   1544.0  P IN B@   \n",
       "3                 3           3.0           3.0         3.0    272.0  P IN C@   \n",
       "4                 4           4.0           4.0         4.0    234.0        S   \n",
       "...             ...           ...           ...         ...      ...      ...   \n",
       "73818         73818           NaN           NaN         NaN      NaN      NaN   \n",
       "73819         73819           NaN           NaN         NaN      NaN      NaN   \n",
       "73820         73820           NaN           NaN         NaN      NaN      NaN   \n",
       "73821         73821           NaN           NaN         NaN      NaN      NaN   \n",
       "73822         73822           NaN           NaN         NaN      NaN      NaN   \n",
       "\n",
       "      lemma word Phones morph  ... actual_lemma_pos extra actual_lemma_phones  \\\n",
       "0         a    a      a   NaN  ...                P   NaN                   a   \n",
       "1         a    a      a   NaN  ...                P   NaN                   a   \n",
       "2         a    a      a   NaN  ...                P   NaN                   a   \n",
       "3         a    a      a   NaN  ...                P   NaN                   a   \n",
       "4         a    a      a   NaN  ...                P   NaN                   a   \n",
       "...     ...  ...    ...   ...  ...              ...   ...                 ...   \n",
       "73818   NaN  NaN    NaN   NaN  ...              NaN   NaN                 NaN   \n",
       "73819   NaN  NaN    NaN   NaN  ...              NaN   NaN                 NaN   \n",
       "73820   NaN  NaN    NaN   NaN  ...              NaN   NaN                 NaN   \n",
       "73821   NaN  NaN    NaN   NaN  ...              NaN   NaN                 NaN   \n",
       "73822   NaN  NaN    NaN   NaN  ...              NaN   NaN               38885   \n",
       "\n",
       "      spacy_lemma nltk_lemma derivational process reason spacy_lemma_2  \\\n",
       "0               a          a          NaN     NaN    NaN             a   \n",
       "1               a          a          NaN     NaN    NaN             a   \n",
       "2               a          a          NaN     NaN    NaN             a   \n",
       "3               a          a          NaN     NaN    NaN             a   \n",
       "4               a          a          NaN     NaN    NaN             a   \n",
       "...           ...        ...          ...     ...    ...           ...   \n",
       "73818         NaN        NaN          NaN     NaN    NaN           NaN   \n",
       "73819         NaN        NaN          NaN     NaN    NaN           NaN   \n",
       "73820         NaN        NaN          NaN     NaN    NaN           NaN   \n",
       "73821         NaN        NaN          NaN     NaN    NaN           NaN   \n",
       "73822         NaN        NaN          NaN     NaN    NaN           NaN   \n",
       "\n",
       "      spacy_pos_2  \n",
       "0               X  \n",
       "1               X  \n",
       "2            NOUN  \n",
       "3               X  \n",
       "4               X  \n",
       "...           ...  \n",
       "73818         NaN  \n",
       "73819         NaN  \n",
       "73820         NaN  \n",
       "73821         NaN  \n",
       "73822         NaN  \n",
       "\n",
       "[73823 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"ita_deriv_9.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc04103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44002it [00:04, 10276.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nana nan\n",
      "nane nan\n",
      "nani nan\n",
      "nani nan\n",
      "nano nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulla nan\n",
      "nulle nan\n",
      "nulli nan\n",
      "nullo nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73823it [00:07, 9854.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['nltk_extra'] = ''\n",
    "for idx, row in tqdm.tqdm(df.iterrows()):\n",
    "    w = row[\"word\"]\n",
    "    l = row[\"nltk_lemma\"]\n",
    "    try:\n",
    "        df.loc[idx, 'nltk_extra'] = w[len(l):]\n",
    "    except:\n",
    "        print(w, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32e7a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73823it [00:02, 28077.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# gcs = dict(zip(zip(df.index, df[\"word\"]), df[\"gramCat\"]))\n",
    "import collections\n",
    "gcs = collections.defaultdict(list)\n",
    "accs = collections.defaultdict(int)\n",
    "\n",
    "for idx, row in tqdm.tqdm(df.iterrows()):\n",
    "    gcs[row[\"word\"]].append(row[\"gramCat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1be29376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.custom_tagger(doc)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacify = {\n",
    "    'B': 'ADV',\n",
    "    'E': 'NOUN',\n",
    "    'G': 'ADJ',\n",
    "    'V': 'VERB',\n",
    "    'I': 'INTJ',\n",
    "    'N': 'PRON',\n",
    "    'S': 'NOUN'\n",
    "}\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "seen = {}\n",
    "\n",
    "@Language.component(\"gtagger\")\n",
    "def custom_tagger(doc):\n",
    "    # Modify POS tags or other annotations as needed\n",
    "    for token in doc:\n",
    "        # Modify token attributes as required\n",
    "        t = doc.text\n",
    "        \n",
    "        if doc in seen:\n",
    "            token.pos_ = seen[doc]\n",
    "            token.tag_ = ''\n",
    "        \n",
    "        if gc := gcs.get(t):\n",
    "            try:\n",
    "                token.pos_ = spacify.get(gc[accs[t] % len(gc)], 'X')\n",
    "                token.tag_ = ''\n",
    "                accs[t] += 1\n",
    "                seen[doc] = token.pos_\n",
    "            except:\n",
    "                print(t, accs[t])\n",
    "        else:\n",
    "            print(token.text)\n",
    "            input()\n",
    "            token.pos_ = 'X'\n",
    "        return doc\n",
    "\n",
    "nlp = spacy.load(\"it_core_news_lg\", disable=['parser', 'ner', 'tagger'])\n",
    "# nlp.initialize()\n",
    "nlp.add_pipe('gtagger', name='gtagger', before='lemmatizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c78b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "821it [00:03, 254.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m w \u001b[38;5;241m=\u001b[39m nlp(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspacy_pos_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mpos_\n\u001b[0;32m----> 6\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspacy_lemma_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlemma_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/layers/concatenate.py:57\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/layers/concatenate.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 57\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     59\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/ml/featureextractor.py:21\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, docs, is_train)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(doc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_array\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mto_array(columns)[doc\u001b[38;5;241m.\u001b[39mstart : doc\u001b[38;5;241m.\u001b[39mend]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/tokens/doc.pyx:969\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/spacy/tokens/doc.pyx:1009\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['spacy_lemma_2'] = ''\n",
    "df['spacy_pos_2'] = ''\n",
    "for idx, row in tqdm.tqdm(df.iterrows()):\n",
    "    w = nlp(row[\"word\"])[0]\n",
    "    df.loc[idx, 'spacy_pos_2'] = w.pos_\n",
    "    df.loc[idx, 'spacy_lemma_2'] = nlp(row[\"word\"])[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c538cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fqTot</th>\n",
       "      <th>gramCat</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>Phones</th>\n",
       "      <th>morph</th>\n",
       "      <th>pos</th>\n",
       "      <th>...</th>\n",
       "      <th>actual_lemma_pos</th>\n",
       "      <th>extra</th>\n",
       "      <th>actual_lemma_phones</th>\n",
       "      <th>spacy_lemma</th>\n",
       "      <th>nltk_lemma</th>\n",
       "      <th>derivational</th>\n",
       "      <th>process</th>\n",
       "      <th>reason</th>\n",
       "      <th>spacy_lemma_2</th>\n",
       "      <th>spacy_pos_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50518.0</td>\n",
       "      <td>P</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>P IN P@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>P IN B@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>P IN C@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>S</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>...</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73818</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73822</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73823 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0    fqTot  gramCat lemma word  \\\n",
       "0               0.0           0.0         0.0  50518.0        P     a    a   \n",
       "1               1.0           1.0         1.0   5219.0  P IN P@     a    a   \n",
       "2               2.0           2.0         2.0   1544.0  P IN B@     a    a   \n",
       "3               3.0           3.0         3.0    272.0  P IN C@     a    a   \n",
       "4               4.0           4.0         4.0    234.0        S     a    a   \n",
       "...             ...           ...         ...      ...      ...   ...  ...   \n",
       "73818           NaN           NaN         NaN      NaN      NaN   NaN  NaN   \n",
       "73819           NaN           NaN         NaN      NaN      NaN   NaN  NaN   \n",
       "73820           NaN           NaN         NaN      NaN      NaN   NaN  NaN   \n",
       "73821           NaN           NaN         NaN      NaN      NaN   NaN  NaN   \n",
       "73822           NaN           NaN         NaN      NaN      NaN   NaN  NaN   \n",
       "\n",
       "      Phones morph  pos  ... actual_lemma_pos extra actual_lemma_phones  \\\n",
       "0          a   NaN  ADP  ...                P   NaN                   a   \n",
       "1          a   NaN  ADP  ...                P   NaN                   a   \n",
       "2          a   NaN  ADP  ...                P   NaN                   a   \n",
       "3          a   NaN  ADP  ...                P   NaN                   a   \n",
       "4          a   NaN  ADP  ...                P   NaN                   a   \n",
       "...      ...   ...  ...  ...              ...   ...                 ...   \n",
       "73818    NaN   NaN  NaN  ...              NaN   NaN                 NaN   \n",
       "73819    NaN   NaN  NaN  ...              NaN   NaN                 NaN   \n",
       "73820    NaN   NaN  NaN  ...              NaN   NaN                 NaN   \n",
       "73821    NaN   NaN  NaN  ...              NaN   NaN                 NaN   \n",
       "73822    NaN   NaN  NaN  ...              NaN   NaN               38885   \n",
       "\n",
       "      spacy_lemma nltk_lemma derivational process reason spacy_lemma_2  \\\n",
       "0               a          a          NaN     NaN    NaN             a   \n",
       "1               a          a          NaN     NaN    NaN             a   \n",
       "2               a          a          NaN     NaN    NaN             a   \n",
       "3               a          a          NaN     NaN    NaN             a   \n",
       "4               a          a          NaN     NaN    NaN             a   \n",
       "...           ...        ...          ...     ...    ...           ...   \n",
       "73818         NaN        NaN          NaN     NaN    NaN                 \n",
       "73819         NaN        NaN          NaN     NaN    NaN                 \n",
       "73820         NaN        NaN          NaN     NaN    NaN                 \n",
       "73821         NaN        NaN          NaN     NaN    NaN                 \n",
       "73822         NaN        NaN          NaN     NaN    NaN                 \n",
       "\n",
       "      spacy_pos_2  \n",
       "0               X  \n",
       "1               X  \n",
       "2            NOUN  \n",
       "3               X  \n",
       "4               X  \n",
       "...           ...  \n",
       "73818              \n",
       "73819              \n",
       "73820              \n",
       "73821              \n",
       "73822              \n",
       "\n",
       "[73823 rows x 34 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac82635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73823it [00:21, 3399.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_excel(\"ita_deriv_6.xlsx\")\n",
    "\n",
    "# suffixes = ['eggi', 'ific', 'izz', 'aggi', 'aggin', 'ai', 'aiol', 'anz', 'enz', 'eri', 'ezz', 'i\\'', 'ier', 'ifici', 'in', 'ism', 'esim', 'ist', 'ita\\'', 'eta\\'', 'ta\\'', 'ituden', 'etudin', 'izi', 'uzi', 'ment', 'toi', 'tor', 'sor', 'tric', 'tori', 'ur', 'zion', 'sion', 'ace', 'al', 'ar', 'ari', 'atori', 'bil', 'es', 'an', 'in', 'asc', 'esc', 'evol', 'ic', 'ier', 'ifer', 'ific', 'efic', 'il', 'iv', 'izi', 'os', 'str']\n",
    "\n",
    "suffixes = {\n",
    "    \"E V event/process\": [\"izzare\", \"ificare\"],\n",
    "    \"E E pertaining to/follwoing\": [\"ismo\", \"esimo\"],\n",
    "    \"E E actively involved in\": [\"ista\"],\n",
    "    \"E E quantity of\": [\"aglia\", \"ame\", \"ume\", \"ata\"],\n",
    "    \"E E hit\": [\"ata\"],\n",
    "    \"E E place with\": [\"eta\", \"eto\"],\n",
    "    \"E E place for\": [\"ile\"],\n",
    "    \"E E containing\": [\"ato\"],\n",
    "    \"E E feminine\": [\"essa\"],\n",
    "    \"E G related to\": [\"ale\", \"torio\", \"ino\", \"eo\", \"are\", \"ano\", \n",
    "                            \"esco\", \"aso\", \"ico\", \"istico\", \"ivo\", \n",
    "                            \"izio\", \"'ile\", \"oso\"],\n",
    "    \"E G similar to\": [\"aceo\", \"ino\", \"oide\", \"igno\", \"are\"],\n",
    "    \"E G belonging to\": [\"ardo\", \"asco\", \"ico\", \"ano\"],\n",
    "    \"E G inhabitant of\": [\"ano\", \"ino\", \"etano\", \"itano\", \"aneo\", \"eo\", \"ese\", \"ate\", \n",
    "                         \"ota\", \"are\", \"esco\", \"ico\", \"eno\"],\n",
    "    \"V N effect of\": [\"ata\", \"ione\", \"menti\", \"aggi\", \"ura\", \"nza\", \"io\", \"eria\"],\n",
    "    \"V N state of\": [\"ato\", \"nza\", \"ia\", \"io\", \"ore\"],\n",
    "    \"V N related to\": [\"toio\", \"toia\", \"torio\"],\n",
    "    \"V N the point of\": [\"ando\"],\n",
    "    \"V N agent of\": [\"tore\", \"trice\", \"iere\", \"iero\", \"ante\", \"aro\"],\n",
    "    \"V G referring to\": [\"evole\", \"ivo\", \"torio\", \"ario\"],\n",
    "    \"V V grade of\": [\"ellare\", \"arellare\", \"erellare\", \"icchiare\", \"acchiare\", \"ettare\", \"ellar\", \"ettar\"],\n",
    "    \"G N quality of\": [\"ita'\", \"udine\", \"ezza\", \"izia\", \"igia\", \"aggine\", \"ia\"],\n",
    "    \"G V change status of\": [\"izzare\", \"ificare\"],\n",
    "    \"G N phenomenon of\": [\"ismo\", \"esimo\"],\n",
    "    \"G N actively involved in\": [\"ista\"],\n",
    "    \"G G manner of\": []\n",
    "}\n",
    "\n",
    "# df['actual_lemma'] = ''\n",
    "df['derivational'] = ''\n",
    "df['process'] = ''\n",
    "df['reason'] = ''\n",
    "\n",
    "for idx, row in tqdm.tqdm(df.iterrows()):\n",
    "    w = row['word']\n",
    "    try:\n",
    "        for typ, suffs in suffixes.items():\n",
    "            for s in suffs:\n",
    "                if s in row['nltk_extra']:\n",
    "#                     goal_lemma = w[:w.index(s)]\n",
    "#                     if lemma := find_closest_lemma(goal_lemma):\n",
    "        #                 print(goal_lemma, lemma)\n",
    "        #                 input()\n",
    "#                         df.loc[idx, 'actual_lemma'] = lemma\n",
    "#                         df.loc[idx, 'derivational'] = s\n",
    "                    t1, t2, *reason = typ.split()\n",
    "                    if row[\"gramCat\"] == t2: # todo use t1\n",
    "                        df.loc[idx, 'process'] = f\"{t1} => {t2}\"\n",
    "                        df.loc[idx, 'reason'] = ' '.join(reason)\n",
    "#                     break\n",
    "#         for p in prefixes:\n",
    "#             ...\n",
    "    except Exception as e:\n",
    "        print(e, idx, w) #, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50417255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"ita_deriv.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de563d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fqTot</th>\n",
       "      <th>gramCat</th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>Phones</th>\n",
       "      <th>morph</th>\n",
       "      <th>...</th>\n",
       "      <th>extra</th>\n",
       "      <th>actual_lemma_phones</th>\n",
       "      <th>spacy_lemma</th>\n",
       "      <th>nltk_lemma</th>\n",
       "      <th>derivational</th>\n",
       "      <th>process</th>\n",
       "      <th>reason</th>\n",
       "      <th>spacy_lemma_2</th>\n",
       "      <th>spacy_pos_2</th>\n",
       "      <th>nltk_extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50518.0</td>\n",
       "      <td>P</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>P IN P@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>P IN B@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>P IN C@</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>S</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73818</th>\n",
       "      <td>73818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73819</th>\n",
       "      <td>73819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73820</th>\n",
       "      <td>73820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73821</th>\n",
       "      <td>73821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73822</th>\n",
       "      <td>73822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73823 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0    fqTot  gramCat  \\\n",
       "0                 0           0.0           0.0         0.0  50518.0        P   \n",
       "1                 1           1.0           1.0         1.0   5219.0  P IN P@   \n",
       "2                 2           2.0           2.0         2.0   1544.0  P IN B@   \n",
       "3                 3           3.0           3.0         3.0    272.0  P IN C@   \n",
       "4                 4           4.0           4.0         4.0    234.0        S   \n",
       "...             ...           ...           ...         ...      ...      ...   \n",
       "73818         73818           NaN           NaN         NaN      NaN      NaN   \n",
       "73819         73819           NaN           NaN         NaN      NaN      NaN   \n",
       "73820         73820           NaN           NaN         NaN      NaN      NaN   \n",
       "73821         73821           NaN           NaN         NaN      NaN      NaN   \n",
       "73822         73822           NaN           NaN         NaN      NaN      NaN   \n",
       "\n",
       "      lemma word Phones morph  ... extra actual_lemma_phones spacy_lemma  \\\n",
       "0         a    a      a   NaN  ...   NaN                   a           a   \n",
       "1         a    a      a   NaN  ...   NaN                   a           a   \n",
       "2         a    a      a   NaN  ...   NaN                   a           a   \n",
       "3         a    a      a   NaN  ...   NaN                   a           a   \n",
       "4         a    a      a   NaN  ...   NaN                   a           a   \n",
       "...     ...  ...    ...   ...  ...   ...                 ...         ...   \n",
       "73818   NaN  NaN    NaN   NaN  ...   NaN                 NaN         NaN   \n",
       "73819   NaN  NaN    NaN   NaN  ...   NaN                 NaN         NaN   \n",
       "73820   NaN  NaN    NaN   NaN  ...   NaN                 NaN         NaN   \n",
       "73821   NaN  NaN    NaN   NaN  ...   NaN                 NaN         NaN   \n",
       "73822   NaN  NaN    NaN   NaN  ...   NaN               38885         NaN   \n",
       "\n",
       "      nltk_lemma derivational process reason spacy_lemma_2 spacy_pos_2  \\\n",
       "0              a                                         a           X   \n",
       "1              a                                         a           X   \n",
       "2              a                                         a        NOUN   \n",
       "3              a                                         a           X   \n",
       "4              a                                         a           X   \n",
       "...          ...          ...     ...    ...           ...         ...   \n",
       "73818        NaN                                       NaN         NaN   \n",
       "73819        NaN                                       NaN         NaN   \n",
       "73820        NaN                                       NaN         NaN   \n",
       "73821        NaN                                       NaN         NaN   \n",
       "73822        NaN                                       NaN         NaN   \n",
       "\n",
       "      nltk_extra  \n",
       "0                 \n",
       "1                 \n",
       "2                 \n",
       "3                 \n",
       "4                 \n",
       "...          ...  \n",
       "73818             \n",
       "73819             \n",
       "73820             \n",
       "73821             \n",
       "73822             \n",
       "\n",
       "[73823 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
